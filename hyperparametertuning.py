# -*- coding: utf-8 -*-
"""HyperparameterTuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gHjhQSE52R712ZbpfuuXKRGKCNhZiK6i
"""

# Step 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Step 2: Load the Dataset
import pandas as pd

# Replace 'path_to_your_file.csv' with the actual path to your file in Google Drive
file_path = '/content/drive/My Drive/Datasets/ASEAN_cleaned.csv'

# Load the dataset into a Pandas DataFrame
data = pd.read_csv(file_path)

# Step 3: Display Dataset Info
print("Dataset Loaded Successfully!")
print("First 5 rows of the dataset:")
print(data.head())
print("\nDataset Info:")
print(data.info())

"""Feature Selection using Recursive Feature Elimination (RFE)"""

import numpy as np
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression

# Prepare the Dataset
# Drop rows with missing values
data = data.dropna()

# Define X (features) and y (target)
X = data.select_dtypes(include=[np.number]).drop(columns=["Food supply (kcal)"])
y = data["Food supply (kcal)"]

# Feature Selection using RFE
base_model = LinearRegression()  # Use Linear Regression as the base model for RFE
rfe_selector = RFE(estimator=base_model, n_features_to_select=4)  # Select top 4 features
rfe_selector.fit(X, y)

# Retrieve Selected Features
selected_features = X.columns[rfe_selector.support_]
print("Selected Features using RFE:", selected_features)

# Reduce the dataset to selected features
X_rfe = X[selected_features]

# Display the reduced feature set
print("\nReduced Dataset with Selected Features:")
print(X_rfe.head())

"""Random Forest Regressor (Holdout Validation)"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Holdout validation
X_train, X_temp, y_train, y_temp = train_test_split(X_rfe, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)

# Train Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Evaluate on validation and test sets
y_val_pred = rf_model.predict(X_val)
y_test_pred = rf_model.predict(X_test)

val_metrics = {
    "MAE": mean_absolute_error(y_val, y_val_pred),
    "MSE": mean_squared_error(y_val, y_val_pred),
    "R²": r2_score(y_val, y_val_pred),
}
test_metrics = {
    "MAE": mean_absolute_error(y_test, y_test_pred),
    "MSE": mean_squared_error(y_test, y_test_pred),
    "R²": r2_score(y_test, y_test_pred),
}

print("Random Forest - Holdout Validation Metrics:")
print("Validation:", val_metrics)
print("Test:", test_metrics)

"""Random Forest Regressor (K-Fold Cross-Validation)"""

from sklearn.model_selection import KFold, cross_val_score

# K-Fold Cross Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(rf_model, X_rfe, y, scoring='neg_mean_squared_error', cv=kf)

print("Random Forest - K-Fold Cross-Validation Metrics:")
print("Mean MSE:", -np.mean(cv_scores))
print("Standard Deviation of MSE:", np.std(cv_scores))

"""Linear Regression (Holdout Validation)"""

# Train Linear Regression model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Evaluate on validation and test sets
y_val_pred = lr_model.predict(X_val)
y_test_pred = lr_model.predict(X_test)

val_metrics = {
    "MAE": mean_absolute_error(y_val, y_val_pred),
    "MSE": mean_squared_error(y_val, y_val_pred),
    "R²": r2_score(y_val, y_val_pred),
}
test_metrics = {
    "MAE": mean_absolute_error(y_test, y_test_pred),
    "MSE": mean_squared_error(y_test, y_test_pred),
    "R²": r2_score(y_test, y_test_pred),
}

print("Linear Regression - Holdout Validation Metrics:")
print("Validation:", val_metrics)
print("Test:", test_metrics)

"""Linear Regression (K-Fold Cross-Validation)"""

# K-Fold Cross Validation
cv_scores = cross_val_score(lr_model, X_rfe, y, scoring='neg_mean_squared_error', cv=kf)

print("Linear Regression - K-Fold Cross-Validation Metrics:")
print("Mean MSE:", -np.mean(cv_scores))
print("Standard Deviation of MSE:", np.std(cv_scores))

"""K-Nearest Neighbors Regressor (Holdout Validation)"""

from sklearn.neighbors import KNeighborsRegressor

# Train KNN model
knn_model = KNeighborsRegressor(n_neighbors=5)
knn_model.fit(X_train, y_train)

# Evaluate on validation and test sets
y_val_pred = knn_model.predict(X_val)
y_test_pred = knn_model.predict(X_test)

val_metrics = {
    "MAE": mean_absolute_error(y_val, y_val_pred),
    "MSE": mean_squared_error(y_val, y_val_pred),
    "R²": r2_score(y_val, y_val_pred),
}
test_metrics = {
    "MAE": mean_absolute_error(y_test, y_test_pred),
    "MSE": mean_squared_error(y_test, y_test_pred),
    "R²": r2_score(y_test, y_test_pred),
}

print("K-Nearest Neighbors - Holdout Validation Metrics:")
print("Validation:", val_metrics)
print("Test:", test_metrics)

"""K-Nearest Neighbors Regressor (K-Fold Cross-Validation)"""

# K-Fold Cross Validation
cv_scores = cross_val_score(knn_model, X_rfe, y, scoring='neg_mean_squared_error', cv=kf)

print("K-Nearest Neighbors - K-Fold Cross-Validation Metrics:")
print("Mean MSE:", -np.mean(cv_scores))
print("Standard Deviation of MSE:", np.std(cv_scores))

"""Support Vector Machine Regressor (Holdout Validation)"""

from sklearn.svm import SVR

# Train SVM model
svm_model = SVR(kernel='rbf', C=1.0, gamma=0.1)
svm_model.fit(X_train, y_train)

# Evaluate on validation and test sets
y_val_pred = svm_model.predict(X_val)
y_test_pred = svm_model.predict(X_test)

val_metrics = {
    "MAE": mean_absolute_error(y_val, y_val_pred),
    "MSE": mean_squared_error(y_val, y_val_pred),
    "R²": r2_score(y_val, y_val_pred),
}
test_metrics = {
    "MAE": mean_absolute_error(y_test, y_test_pred),
    "MSE": mean_squared_error(y_test, y_test_pred),
    "R²": r2_score(y_test, y_test_pred),
}

print("SVM - Holdout Validation Metrics:")
print("Validation:", val_metrics)
print("Test:", test_metrics)

"""Support Vector Machine Regressor (K-Fold Cross-Validation)"""

# K-Fold Cross Validation
cv_scores = cross_val_score(svm_model, X_rfe, y, scoring='neg_mean_squared_error', cv=kf)

print("SVM - K-Fold Cross-Validation Metrics:")
print("Mean MSE:", -np.mean(cv_scores))
print("Standard Deviation of MSE:", np.std(cv_scores))

"""Random Forest Hyperparameter Tuning"""

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Define hyperparameter grids for Random Forest
rf_param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

# Grid Search for Random Forest
rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42), rf_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
rf_grid_search.fit(X_train, y_train)

print("Random Forest - Best Parameters (Grid Search):", rf_grid_search.best_params_)

# Random Search for Random Forest
rf_random_param_grid = {
    'n_estimators': [int(x) for x in np.linspace(50, 200, 10)],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}
rf_random_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), rf_random_param_grid, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)
rf_random_search.fit(X_train, y_train)

print("Random Forest - Best Parameters (Random Search):", rf_random_search.best_params_)

"""k-Nearest Neighbor Hyperparameter Tuning"""

# Define hyperparameter grids for KNN
knn_param_grid = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance']
}

# Grid Search for KNN
knn_grid_search = GridSearchCV(KNeighborsRegressor(), knn_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
knn_grid_search.fit(X_train, y_train)

print("KNN - Best Parameters (Grid Search):", knn_grid_search.best_params_)

# Random Search for KNN
knn_random_param_grid = {
    'n_neighbors': [int(x) for x in np.linspace(3, 9, 5)],
    'weights': ['uniform', 'distance']
}
knn_random_search = RandomizedSearchCV(KNeighborsRegressor(), knn_random_param_grid, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)
knn_random_search.fit(X_train, y_train)

print("KNN - Best Parameters (Random Search):", knn_random_search.best_params_)

"""Support Vector Machine Hyperparameter Tuning"""

# Define hyperparameter grids for SVM
svm_param_grid = {
    'C': [0.1, 1, 10],
    'gamma': [0.01, 0.1, 1],
    'kernel': ['linear', 'rbf']
}

# Grid Search for SVM
svm_grid_search = GridSearchCV(SVR(), svm_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
svm_grid_search.fit(X_train, y_train)

print("SVM - Best Parameters (Grid Search):", svm_grid_search.best_params_)

# Random Search for SVM
svm_random_param_grid = {
    'C': np.logspace(-2, 2, 10),
    'gamma': np.logspace(-2, 2, 10),
    'kernel': ['linear', 'rbf']
}
svm_random_search = RandomizedSearchCV(SVR(), svm_random_param_grid, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)
svm_random_search.fit(X_train, y_train)

print("SVM - Best Parameters (Random Search):", svm_random_search.best_params_)

"""Performance Comparison: Default vs Tuned Model"""

# Train and evaluate tuned Random Forest model (example for Random Forest)
rf_best = RandomForestRegressor(**rf_grid_search.best_params_, random_state=42)
rf_best.fit(X_train, y_train)

# Predict and evaluate
y_test_pred_tuned = rf_best.predict(X_test)
tuned_metrics = {
    "MAE": mean_absolute_error(y_test, y_test_pred_tuned),
    "MSE": mean_squared_error(y_test, y_test_pred_tuned),
    "R²": r2_score(y_test, y_test_pred_tuned),
}

print("Random Forest - Tuned Metrics (Grid Search):")
print(tuned_metrics)

# Compare default vs. tuned model
print("\nRandom Forest - Default Metrics:")
print(test_metrics)  # From your earlier code

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Function to evaluate a model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    return {
        "MAE": mean_absolute_error(y_test, y_pred),
        "MSE": mean_squared_error(y_test, y_pred),
        "R²": r2_score(y_test, y_pred),
    }

# Random Forest
print("\n--- Random Forest ---")
# Default
rf_default = RandomForestRegressor(random_state=42)
rf_default.fit(X_train, y_train)
rf_default_metrics = evaluate_model(rf_default, X_test, y_test)

# Grid Search Tuned
rf_best_grid = RandomForestRegressor(**rf_grid_search.best_params_, random_state=42)
rf_best_grid.fit(X_train, y_train)
rf_grid_metrics = evaluate_model(rf_best_grid, X_test, y_test)

# Random Search Tuned
rf_best_random = RandomForestRegressor(**rf_random_search.best_params_, random_state=42)
rf_best_random.fit(X_train, y_train)
rf_random_metrics = evaluate_model(rf_best_random, X_test, y_test)

print("Default:", rf_default_metrics)
print("Grid Search:", rf_grid_metrics)
print("Random Search:", rf_random_metrics)

# K-Nearest Neighbors
print("\n--- K-Nearest Neighbors ---")
# Default
knn_default = KNeighborsRegressor()
knn_default.fit(X_train, y_train)
knn_default_metrics = evaluate_model(knn_default, X_test, y_test)

# Grid Search Tuned
knn_best_grid = KNeighborsRegressor(**knn_grid_search.best_params_)
knn_best_grid.fit(X_train, y_train)
knn_grid_metrics = evaluate_model(knn_best_grid, X_test, y_test)

# Random Search Tuned
knn_best_random = KNeighborsRegressor(**knn_random_search.best_params_)
knn_best_random.fit(X_train, y_train)
knn_random_metrics = evaluate_model(knn_best_random, X_test, y_test)

print("Default:", knn_default_metrics)
print("Grid Search:", knn_grid_metrics)
print("Random Search:", knn_random_metrics)

# Support Vector Machine
print("\n--- Support Vector Machine ---")
# Default
svm_default = SVR()
svm_default.fit(X_train, y_train)
svm_default_metrics = evaluate_model(svm_default, X_test, y_test)

# Grid Search Tuned
svm_best_grid = SVR(**svm_grid_search.best_params_)
svm_best_grid.fit(X_train, y_train)
svm_grid_metrics = evaluate_model(svm_best_grid, X_test, y_test)

# Random Search Tuned
svm_best_random = SVR(**svm_random_search.best_params_)
svm_best_random.fit(X_train, y_train)
svm_random_metrics = evaluate_model(svm_best_random, X_test, y_test)

print("Default:", svm_default_metrics)
print("Grid Search:", svm_grid_metrics)
print("Random Search:", svm_random_metrics)

# Summary of Results
summary = {
    "Algorithm": ["Random Forest", "KNN", "SVM"],
    "Default MAE": [rf_default_metrics["MAE"], knn_default_metrics["MAE"], svm_default_metrics["MAE"]],
    "Grid Search MAE": [rf_grid_metrics["MAE"], knn_grid_metrics["MAE"], svm_grid_metrics["MAE"]],
    "Random Search MAE": [rf_random_metrics["MAE"], knn_random_metrics["MAE"], svm_random_metrics["MAE"]],
    "Default R²": [rf_default_metrics["R²"], knn_default_metrics["R²"], svm_default_metrics["R²"]],
    "Grid Search R²": [rf_grid_metrics["R²"], knn_grid_metrics["R²"], svm_grid_metrics["R²"]],
    "Random Search R²": [rf_random_metrics["R²"], knn_random_metrics["R²"], svm_random_metrics["R²"]],
}

import pandas as pd
results_df = pd.DataFrame(summary)
print("\nPerformance Comparison:")
print(results_df)

# prompt: Do visualisation for performance comparison

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'results_df' is the DataFrame from your previous code
# ... (Your existing code) ...

# Plotting MAE Comparison
plt.figure(figsize=(10, 6))
sns.barplot(x="Algorithm", y="Default MAE", data=results_df, label="Default")
sns.barplot(x="Algorithm", y="Grid Search MAE", data=results_df, label="Grid Search")
sns.barplot(x="Algorithm", y="Random Search MAE", data=results_df, label="Random Search")
plt.title("MAE Comparison for Different Algorithms")
plt.ylabel("Mean Absolute Error")
plt.legend()
plt.show()


# Plotting R-squared Comparison
plt.figure(figsize=(10, 6))
sns.barplot(x="Algorithm", y="Default R²", data=results_df, label="Default")
sns.barplot(x="Algorithm", y="Grid Search R²", data=results_df, label="Grid Search")
sns.barplot(x="Algorithm", y="Random Search R²", data=results_df, label="Random Search")
plt.title("R-squared Comparison for Different Algorithms")
plt.ylabel("R-squared")
plt.legend()
plt.show()