# -*- coding: utf-8 -*-
"""FeatureSelection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lKd-cRFiYQranGkOZKL7A7I7X-_I1ZTT
"""

# Import Libraries
import pandas as pd
import numpy as np
from sklearn.feature_selection import SelectKBest, f_regression, RFE
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Load the Dataset from Google Drive
file_path = '/content/drive/My Drive/Datasets/ASEAN_cleaned.csv'  # Update the path as necessary
data = pd.read_csv(file_path)

print("Dataset loaded successfully!")

# Prepare the Dataset
# Drop non-numeric columns and handle missing values
numeric_data = data.select_dtypes(include=[np.number]).dropna()

# Define the target variable (y) and features (X)
X = numeric_data.drop(columns=["Food supply (kcal)"])
y = numeric_data["Food supply (kcal)"]

# Filter Method - Correlation Analysis using SelectKBest
filter_selector = SelectKBest(score_func=f_regression, k=4)
X_filter_selected = filter_selector.fit_transform(X, y)
filter_features = X.columns[filter_selector.get_support()]
print("Filter Method (Correlation Analysis) Selected Features:")
print(filter_features)

# Wrapper Method - Recursive Feature Elimination (RFE)
model_lr = LinearRegression()
rfe_selector = RFE(estimator=model_lr, n_features_to_select=4)
X_rfe_selected = rfe_selector.fit_transform(X, y)
rfe_features = X.columns[rfe_selector.get_support()]
print("\nWrapper Method (RFE) Selected Features:")
print(rfe_features)

# Embedded Method - Feature Importance from Tree Models
model_rf = RandomForestRegressor(random_state=42)
model_rf.fit(X, y)
importances = model_rf.feature_importances_
embedded_features = X.columns[np.argsort(importances)[-4:]]  # Top 4 features
print("\nEmbedded Method (Tree Importance) Selected Features:")
print(embedded_features)

# Summarize Selected Features from Each Method
selected_features = {
    "Filter Method (Correlation Analysis)": list(filter_features),
    "Wrapper Method (RFE)": list(rfe_features),
    "Embedded Method (Tree Importance)": list(embedded_features),
}
print("\nSummary of Selected Features:")
print(selected_features)

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pandas as pd

# Step 1: Define a function to evaluate feature selection performance
def evaluate_features(X_selected, y, method_name):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

    # Train a Random Forest Regressor
    model = RandomForestRegressor(random_state=42)
    model.fit(X_train, y_train)

    # Predict on the test set
    y_pred = model.predict(X_test)

    # Compute evaluation metrics
    metrics = {
        "MAE": mean_absolute_error(y_test, y_pred),
        "MSE": mean_squared_error(y_test, y_pred),
        "R²": r2_score(y_test, y_pred),
    }

    print(f"\nPerformance using {method_name}:")
    print(metrics)
    return metrics

# Step 2: Evaluate the performance of each feature selection method
print("\nEvaluating Feature Selection Performance:")

# Filter Method
filter_metrics = evaluate_features(X[filter_features], y, "Filter Method (Correlation Analysis)")

# Wrapper Method (RFE)
rfe_metrics = evaluate_features(X[rfe_features], y, "Wrapper Method (RFE)")

# Embedded Method (Tree Importance)
embedded_metrics = evaluate_features(X[embedded_features], y, "Embedded Method (Tree Importance)")

# Step 3: Summarize and Compare Performance
comparison = pd.DataFrame({
    "Feature Selection Method": ["Filter Method", "Wrapper Method", "Embedded Method"],
    "MAE": [filter_metrics["MAE"], rfe_metrics["MAE"], embedded_metrics["MAE"]],
    "MSE": [filter_metrics["MSE"], rfe_metrics["MSE"], embedded_metrics["MSE"]],
    "R²": [filter_metrics["R²"], rfe_metrics["R²"], embedded_metrics["R²"]],
})

print("\nFeature Selection Performance Comparison:")
print(comparison)

# Step 4: Visualization (Optional)
import matplotlib.pyplot as plt

# Plot the MAE for comparison
comparison.plot(x="Feature Selection Method", y="MAE", kind="bar", legend=False, figsize=(10, 6))
plt.title("Feature Selection Performance Comparison - MAE")
plt.ylabel("Mean Absolute Error")
plt.xlabel("Feature Selection Method")
plt.grid(axis="y")
plt.show()

# Plot the R² for comparison
comparison.plot(x="Feature Selection Method", y="R²", kind="bar", legend=False, figsize=(10, 6))
plt.title("Feature Selection Performance Comparison - R²")
plt.ylabel("R² Score")
plt.xlabel("Feature Selection Method")
plt.grid(axis="y")
plt.show()